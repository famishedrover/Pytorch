{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets,transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capsule Conv Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleConvLayer(nn.Module) :\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super(CapsuleConvLayer,self).__init__()\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(in_channels=in_channels,\n",
    "                              out_channels = out_channels,\n",
    "                              kernel_size = 9,\n",
    "                              stride=1,\n",
    "                              bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.relu(self.conv0(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capsule Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvUnit(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(ConvUnit,self).__init__()\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(in_channels=in_channels,\n",
    "                              out_channels=32,\n",
    "                              kernel_size=9,\n",
    "                              stride=2,\n",
    "                              bias=True)\n",
    "    def forward(self,x):\n",
    "        return self.conv0(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLayer(nn.Module):\n",
    "    def __init__(self,in_units,in_channels,\n",
    "                num_units,unit_size,\n",
    "                use_routing):\n",
    "        super(CapsuleLayer,self).__init__()\n",
    "        \n",
    "        self.in_units = in_units\n",
    "        self.in_channels = in_channels\n",
    "        self.num_units = num_units\n",
    "        self.use_routing = use_routing\n",
    "        \n",
    "        if self.use_routing :\n",
    "            self.W = nn.Parameter(torch.randn(1,\n",
    "                                             in_channels,\n",
    "                                             num_units,\n",
    "                                             unit_size,\n",
    "                                             in_units))\n",
    "        else :\n",
    "            def create_conv_unit(unit_id):\n",
    "                unit = ConvUnit(in_channels=in_channels)\n",
    "                self.add_module(\"unit_\"+str(unit_id),\n",
    "                               unit)\n",
    "                return unit\n",
    "            \n",
    "            self.units = [create_conv_unit(i) for i in range(self.num_units)]\n",
    "    \n",
    "    @staticmethod\n",
    "    def squash(s):\n",
    "        #Eq 1 from paper\n",
    "        mag_s_j = torch.sum(s**2,dim=2,keepdim=True)\n",
    "        mag = torch.sqrt(mag_s_j)\n",
    "        \n",
    "        s = (mag_s_j/(1+mag_s_j))*(s/mag)\n",
    "        return s\n",
    "    \n",
    "    def forward(self,x):\n",
    "        if self.use_routing:\n",
    "            return self.routing(x)\n",
    "        else:\n",
    "            return self.no_routing(x)\n",
    "    \n",
    "    def no_routing(self,x):\n",
    "        #[batch,channels,height,width]\n",
    "\n",
    "        #get output for each unit.\n",
    "        u = [self.units[i](x) for i in range(self.num_units)]\n",
    "        \n",
    "        #stack unit outputs\n",
    "        #[batch,unit,channels,height,width]\n",
    "        u = torch.stack(u,dim=1)\n",
    "        \n",
    "        #Flatten to [batch,unit,output]\n",
    "        u = u.view(x.size(0),self.num_units,-1)\n",
    "        \n",
    "        #return squashed outputs.\n",
    "        return CapsuleLayer.squash(u)\n",
    "    \n",
    "    \n",
    "    def routing(self,x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        #[batch,in_units,features] -> [batch,features,in_units]\n",
    "        x =x.transpose(1,2)\n",
    "        \n",
    "        #Wdotx  = [batch,features,num_units,    unit_size,in_units] dot [batch,features,num_units,    in_units,1]\n",
    "        #output Wdotx = [batch,features,num_units,   unit_size,1]\n",
    "        \n",
    "        #[batch,features,in_units] -> [batch,features,num_units,in_units,1]\n",
    "        x = torch.stack([x]*self.num_units,dim=2).unsqueeze(4)\n",
    "        \n",
    "        # [batch,features,num_units,unit_size,in_units]\n",
    "        W = torch.cat([self.W]*batch_size,dim=0)\n",
    "            \n",
    "        #[batch,features,num_units,   unit_size,1]\n",
    "#         print W.shape\n",
    "#         print x.shape\n",
    "        u_hat= torch.matmul(W,x)\n",
    "        \n",
    "        #routing logits.\n",
    "        #[batch,features,num_units,1]\n",
    "        if torch.cuda.is_available():\n",
    "            b_ij = Variable(torch.zeros(1,self.in_channels,\n",
    "                                   self.num_units,1)).cuda()\n",
    "        else :\n",
    "            b_ij = Variable(torch.zeros(1,self.in_channels,\n",
    "                                   self.num_units,1))\n",
    "            \n",
    "        \n",
    "        num_iterations = 3\n",
    "        \n",
    "        for iteration in range(num_iterations):\n",
    "            #routing_logits->softmax\n",
    "            #[batch,features,num_units,1,1]\n",
    "            c_ij = F.softmax(b_ij)\n",
    "            c_ij = torch.cat([c_ij]*batch_size,dim=0).unsqueeze(4)\n",
    "            \n",
    "            #apply routing to weighted_inputs u_hat\n",
    "            #[batch,1,num_units,unit_size,1]\n",
    "            s_j = (c_ij*u_hat).sum(dim=1,keepdim=True)\n",
    "            \n",
    "            #squash\n",
    "            #[batch,1,num_units,unit_size,1]\n",
    "            v_j = CapsuleLayer.squash(s_j)\n",
    "            \n",
    "            #[batch,features,num_units,unit_size,1]\n",
    "            v_j1 = torch.cat([v_j]*self.in_channels,dim=1)\n",
    "            \n",
    "            #batch,features,num_units,1,1 after matmul\n",
    "            #batch,features,num_units,1 after squeeze\n",
    "            #1,features,num_units,1 after mean\n",
    "            u_vj1 = torch.matmul(u_hat.transpose(3,4),v_j1).squeeze(4).mean(dim=0,keepdim=True)\n",
    "            \n",
    "            #update routing \n",
    "            b_ij = b_ij + u_vj1\n",
    "            \n",
    "            \n",
    "        return v_j.squeeze(1)\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL CapsuleNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleNetwork(nn.Module):\n",
    "    def __init__(self,image_width,image_height,\n",
    "                image_channels,\n",
    "                conv_inputs,conv_outputs,\n",
    "                num_primary_units,\n",
    "                primary_unit_size,\n",
    "                num_output_units,\n",
    "                output_unit_size):\n",
    "        super(CapsuleNetwork,self).__init__()\n",
    "        \n",
    "        self.reconstructed_image_count = 0\n",
    "        \n",
    "        self.image_channels = image_channels\n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        \n",
    "        \n",
    "        self.conv1 = CapsuleConvLayer(in_channels=conv_inputs,\n",
    "                                     out_channels=conv_outputs)\n",
    "        \n",
    "        self.primary = CapsuleLayer(in_units=0,\n",
    "                                   in_channels=conv_outputs,\n",
    "                                   num_units=num_primary_units,\n",
    "                                   unit_size=primary_unit_size,\n",
    "                                   use_routing=False)\n",
    "        \n",
    "        self.digits = CapsuleLayer(in_units=num_primary_units,\n",
    "                                  in_channels=primary_unit_size,\n",
    "                                  num_units=num_output_units,\n",
    "                                  unit_size=output_unit_size,\n",
    "                                  use_routing=True)\n",
    "        \n",
    "        reconstruction_size = image_width*image_height*image_channels\n",
    "        \n",
    "        self.reconstruct0 = nn.Linear(num_output_units*output_unit_size,\n",
    "                                     int((reconstruction_size*2)/3))\n",
    "        self.reconstruct1 = nn.Linear(int((reconstruction_size*2)/3),\n",
    "                                     int((reconstruction_size*3)/2))\n",
    "        self.reconstruct2 = nn.Linear(int(reconstruction_size*3)/2,\n",
    "                                     reconstruction_size)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.digits(self.primary(self.conv1(x)))\n",
    "    \n",
    "    def loss(self,images,input,target,size_average=True):\n",
    "        return self.margin_loss(input,target,size_average) + self.reconstruction_loss(images,input,size_average)\n",
    "    \n",
    "    \n",
    "    def margin_loss(self,input,target,size_average):\n",
    "        \n",
    "        batch_size=input.size(0)\n",
    "        \n",
    "        # ||vc|| from paper.\n",
    "        v_mag = torch.sqrt((input**2).sum(dim=2,keepdim=True))\n",
    "        \n",
    "        #calculate left and right max() terms. eq4 paper.\n",
    "        if torch.cuda.is_available():\n",
    "            zero = Variable(torch.zeros(1)).cuda()\n",
    "        else :\n",
    "            zero = Variable(torch.zeros(1))\n",
    "        m_plus = 0.9\n",
    "        m_minus = 0.1\n",
    "        \n",
    "        max_l = torch.max(m_plus - v_mag,zero).view(batch_size,-1)**2\n",
    "        max_r = torch.max(v_mag - m_minus,zero).view(batch_size,-1)**2\n",
    "        \n",
    "        #eq4\n",
    "        loss_lambda = 0.5\n",
    "        T_c = target\n",
    "        L_c = (T_c * max_l) + (loss_lambda * (1-T_c)*max_r)\n",
    "        \n",
    "        if size_average :\n",
    "            L_c = L_c.mean()\n",
    "            \n",
    "        return L_c\n",
    "    \n",
    "    def reconstruction_loss(self,images,input,size_average=True):\n",
    "        #lengths of capsules.\n",
    "        v_mag = torch.sqrt((input**2).sum(dim=2))\n",
    "        \n",
    "        #idx of longest capsule output.\n",
    "        _,v_max_index = v_mag.max(dim=1)\n",
    "        v_max_index = v_max_index.data\n",
    "        \n",
    "        #use this capsules representation to reconstruct image.\n",
    "        batch_size = input.size(0)\n",
    "        all_masked = [None]*batch_size\n",
    "        \n",
    "        for batch_idx in range(batch_size):\n",
    "            #sample from batch.\n",
    "            input_batch = input[batch_idx]\n",
    "            \n",
    "            #copy max capsules idx from this sample.\n",
    "            #leave other caps as zero.\n",
    "            if torch.cuda.is_available():\n",
    "                batch_masked = Variable(torch.zeros(input_batch.size())).cuda()\n",
    "            else :\n",
    "                batch_masked = Variable(torch.zeros(input_batch.size()))\n",
    "                \n",
    "            batch_masked[v_max_index[batch_idx]] = input_batch[v_max_index[batch_idx]]\n",
    "            all_masked[batch_idx] = batch_masked\n",
    "        \n",
    "        #stack masked caps over batch dimen.\n",
    "        masked = torch.stack(all_masked,dim=0)\n",
    "        \n",
    "        #reconstruction.\n",
    "        masked = masked.view(input.size(0),-1)\n",
    "        output = self.relu(self.reconstruct0(masked))\n",
    "        output = self.relu(self.reconstruct1(output))\n",
    "        output = self.sigmoid(self.reconstruct2(output))\n",
    "        \n",
    "        output = output.view(-1,self.image_channels,\n",
    "                            self.image_height,\n",
    "                            self.image_width)\n",
    "        \n",
    "        if self.reconstructed_image_count%10 == 0:\n",
    "            if output.size(1) == 2:\n",
    "                #handle 2 channel images.\n",
    "                \n",
    "                zeros = torch.zeros(output.size(0),-1,output.size(2),output.size(3))\n",
    "                output_image = torch.cat([zeros,output.data],dim=1).cpu()\n",
    "            else:\n",
    "                output_image = output.data.cpu()\n",
    "            vutils.save_image(output_image,\"recontruction_\"+str(self.reconstructed_image_count)+\".png\")\n",
    "        \n",
    "        self.reconstructed_image_count +=1\n",
    "        \n",
    "        #loss is sum sqr. diff. between input and reconstructed image.\n",
    "        error = (output-images).view(output.size(0),-1)\n",
    "        error = error**2\n",
    "        error = torch.sum(error,dim=1)*0.0005\n",
    "\n",
    "        if size_average:\n",
    "            error = error.mean(dim=0)\n",
    "\n",
    "        \n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "test_batch_size = 128\n",
    "early_stop_loss = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,),(0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST('./data',\n",
    "                              train=True,\n",
    "                              download=True,\n",
    "                              transform=dataset_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST('./data',\n",
    "                             train=False,\n",
    "                             download=True,\n",
    "                             transform=dataset_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=test_batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CapsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_inputs=1\n",
    "conv_outputs=256\n",
    "\n",
    "num_primary_units=8\n",
    "primary_unit_size=32*6*6\n",
    "\n",
    "output_unit_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CapsuleNetwork(\n",
      "  (conv1): CapsuleConvLayer(\n",
      "    (conv0): Conv2d (1, 256, kernel_size=(9, 9), stride=(1, 1))\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (primary): CapsuleLayer(\n",
      "    (unit_0): ConvUnit(\n",
      "      (conv0): Conv2d (256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "    )\n",
      "    (unit_1): ConvUnit(\n",
      "      (conv0): Conv2d (256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "    )\n",
      "    (unit_2): ConvUnit(\n",
      "      (conv0): Conv2d (256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "    )\n",
      "    (unit_3): ConvUnit(\n",
      "      (conv0): Conv2d (256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "    )\n",
      "    (unit_4): ConvUnit(\n",
      "      (conv0): Conv2d (256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "    )\n",
      "    (unit_5): ConvUnit(\n",
      "      (conv0): Conv2d (256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "    )\n",
      "    (unit_6): ConvUnit(\n",
      "      (conv0): Conv2d (256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "    )\n",
      "    (unit_7): ConvUnit(\n",
      "      (conv0): Conv2d (256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (digits): CapsuleLayer(\n",
      "  )\n",
      "  (reconstruct0): Linear(in_features=160, out_features=522)\n",
      "  (reconstruct1): Linear(in_features=522, out_features=1176)\n",
      "  (reconstruct2): Linear(in_features=1176, out_features=784)\n",
      "  (relu): ReLU(inplace)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = CapsuleNetwork(image_width=28,\n",
    "                        image_height=28,\n",
    "                        image_channels=1,\n",
    "                        conv_inputs=conv_inputs,\n",
    "                        conv_outputs=conv_outputs,\n",
    "                        num_primary_units=num_primary_units,\n",
    "                        primary_unit_size=primary_unit_size,\n",
    "                        num_output_units=10,\n",
    "                        output_unit_size=output_unit_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    network = network.cuda()\n",
    "print network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(x,length):\n",
    "    batch_size = x.size(0)\n",
    "    \n",
    "    x_one_hot = torch.zeros(batch_size,length)\n",
    "    for i in range(batch_size):\n",
    "        x_one_hot[i,x[i]] = 1.0\n",
    "    return x_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST TEST FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    \n",
    "    test_loss =0\n",
    "    correct = 0\n",
    "    \n",
    "    for data,target in test_loader:\n",
    "        target_indices = target\n",
    "        target_one_hot = to_one_hot(target_indices,length=network.digits.num_units)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data,target = Variable(data,volatile=True).cuda() , Variable(target_one_hot).cuda()\n",
    "        else:\n",
    "            data,target = Variable(data,volatile=True) , Variable(target_one_hot)\n",
    "        \n",
    "        output=network(data)\n",
    "        \n",
    "        test_loss += network.loss(data,output,target,size_average=False).data[0]\n",
    "        \n",
    "        v_mag = torch.sqrt((output**2).sum(dim=2,keepdim=True))\n",
    "        \n",
    "        pred = v_mag.data.max(1,keepdimTrue)[1].cpu()\n",
    "        \n",
    "        correct += pred.eq(target_indices.view_as(pred)).sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print 'Test Set: Average Loss: {:.4f},Accuracy :{}/{} ({:.0f}%)'.format(test_loss,correct,len(test_loader.dataset),100.*correct/len(test_loader.dataset))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    optimizer = optim.Adam(network.parameters(),lr=learning_rate)\n",
    "    \n",
    "    last_loss = None\n",
    "    log_interval = 1\n",
    "    \n",
    "    network.train()\n",
    "    \n",
    "    for batch_idx , (data,target) in enumerate(train_loader):\n",
    "        target_one_hot = to_one_hot(target,length=network.digits.num_units)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data,target = Variable(data).cuda(),Variable(target_one_hot).cuda()\n",
    "        else:\n",
    "            data,target = Variable(data),Variable(target_one_hot)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output=network(data)\n",
    "        \n",
    "        loss = network.loss(data,output,target)\n",
    "        print loss.shape\n",
    "        loss.backward()\n",
    "        \n",
    "        last_loss = loss.data[0]\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print 'Train Epoch: {} [{}/{} ({:.0f}%)] \\t Loss: {:.6f}'.format(epoch,\n",
    "                                                                            batch_idx*len(data),\n",
    "                                                                            len(train_loader.dataset),\n",
    "                                                                            100.*batch_idx/len(train_loader),\n",
    "                                                                            loss.data[0])\n",
    "        if last_loss < early_stop_loss :\n",
    "            break\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:94: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "Train Epoch: 1 [0/60000 (0%)] \t Loss: 0.561774\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b8da8fce7766>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlast_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-cbadfc6d855c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-60c0c08a0f60>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-29e310469c96>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_routing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mno_routing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-29e310469c96>\u001b[0m in \u001b[0;36mno_routing\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m#get output for each unit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m#stack unit outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a903c4846e6b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m                               bias=True)\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/modules/conv.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 277\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    last_loss = train(epoch)\n",
    "    test()\n",
    "    \n",
    "    if last_loss < early_stop_loss:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
