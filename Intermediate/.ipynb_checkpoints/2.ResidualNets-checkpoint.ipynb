{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParams\n",
    "batch_size = 100\n",
    "lr = 0.001\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(40),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data',\n",
    "                                train=True,\n",
    "                                transform = transform,\n",
    "                                download = True)\n",
    "test_dataset = datasets.CIFAR10(root='./data',\n",
    "                               train=False,\n",
    "                               transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          shuffle=True,\n",
    "                                          batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         shuffle=False,\n",
    "                                         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv3x3 block\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Block\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,stride=1,downsample=None):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "        \n",
    "        self.conv1 = conv3x3(in_channels,out_channels,stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = conv3x3(out_channels,out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "    \n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample :\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        out += residual \n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[0], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[1], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        \n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL :\n",
    "resnet = ResNet( ResidualBlock, [2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss & Optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam( resnet.parameters() , lr=lr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1] , Batch: [10/500] , loss: [1.9877]\n",
      "Epoch: [1/1] , Batch: [20/500] , loss: [1.9489]\n",
      "Epoch: [1/1] , Batch: [30/500] , loss: [1.9679]\n",
      "Epoch: [1/1] , Batch: [40/500] , loss: [2.0464]\n",
      "Epoch: [1/1] , Batch: [50/500] , loss: [2.1030]\n",
      "Epoch: [1/1] , Batch: [60/500] , loss: [2.0872]\n",
      "Epoch: [1/1] , Batch: [70/500] , loss: [2.0103]\n",
      "Epoch: [1/1] , Batch: [80/500] , loss: [2.0163]\n",
      "Epoch: [1/1] , Batch: [90/500] , loss: [1.9286]\n",
      "Epoch: [1/1] , Batch: [100/500] , loss: [2.0782]\n",
      "Epoch: [1/1] , Batch: [110/500] , loss: [2.1005]\n",
      "Epoch: [1/1] , Batch: [120/500] , loss: [1.9741]\n",
      "Epoch: [1/1] , Batch: [130/500] , loss: [2.0976]\n",
      "Epoch: [1/1] , Batch: [140/500] , loss: [1.9934]\n",
      "Epoch: [1/1] , Batch: [150/500] , loss: [2.0571]\n",
      "Epoch: [1/1] , Batch: [160/500] , loss: [1.9970]\n",
      "Epoch: [1/1] , Batch: [170/500] , loss: [2.0400]\n",
      "Epoch: [1/1] , Batch: [180/500] , loss: [1.9703]\n",
      "Epoch: [1/1] , Batch: [190/500] , loss: [2.0476]\n",
      "Epoch: [1/1] , Batch: [200/500] , loss: [1.9920]\n",
      "Epoch: [1/1] , Batch: [210/500] , loss: [2.0284]\n",
      "Epoch: [1/1] , Batch: [220/500] , loss: [2.0029]\n",
      "Epoch: [1/1] , Batch: [230/500] , loss: [1.9909]\n",
      "Epoch: [1/1] , Batch: [240/500] , loss: [2.1442]\n",
      "Epoch: [1/1] , Batch: [250/500] , loss: [2.0217]\n",
      "Epoch: [1/1] , Batch: [260/500] , loss: [1.9831]\n",
      "Epoch: [1/1] , Batch: [270/500] , loss: [2.1351]\n",
      "Epoch: [1/1] , Batch: [280/500] , loss: [1.9766]\n",
      "Epoch: [1/1] , Batch: [290/500] , loss: [2.0033]\n",
      "Epoch: [1/1] , Batch: [300/500] , loss: [2.0257]\n",
      "Epoch: [1/1] , Batch: [310/500] , loss: [1.9745]\n",
      "Epoch: [1/1] , Batch: [320/500] , loss: [2.0074]\n",
      "Epoch: [1/1] , Batch: [330/500] , loss: [1.9545]\n",
      "Epoch: [1/1] , Batch: [340/500] , loss: [2.0007]\n",
      "Epoch: [1/1] , Batch: [350/500] , loss: [2.0280]\n",
      "Epoch: [1/1] , Batch: [360/500] , loss: [2.0128]\n",
      "Epoch: [1/1] , Batch: [370/500] , loss: [1.9935]\n",
      "Epoch: [1/1] , Batch: [380/500] , loss: [1.9679]\n",
      "Epoch: [1/1] , Batch: [390/500] , loss: [1.9592]\n",
      "Epoch: [1/1] , Batch: [400/500] , loss: [2.0433]\n",
      "Epoch: [1/1] , Batch: [410/500] , loss: [1.9532]\n",
      "Epoch: [1/1] , Batch: [420/500] , loss: [1.9896]\n",
      "Epoch: [1/1] , Batch: [430/500] , loss: [1.9795]\n",
      "Epoch: [1/1] , Batch: [440/500] , loss: [1.9924]\n",
      "Epoch: [1/1] , Batch: [450/500] , loss: [2.0121]\n",
      "Epoch: [1/1] , Batch: [460/500] , loss: [1.9279]\n",
      "Epoch: [1/1] , Batch: [470/500] , loss: [1.9542]\n",
      "Epoch: [1/1] , Batch: [480/500] , loss: [2.0905]\n",
      "Epoch: [1/1] , Batch: [490/500] , loss: [2.0361]\n",
      "Epoch: [1/1] , Batch: [500/500] , loss: [2.1112]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in (range(epochs)):\n",
    "    \n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #Forward->loss->Backprop->Optim\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet(images)\n",
    "        \n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        #learning rate decay\n",
    "        if (epoch+1)%1 == 0:\n",
    "            lr /=3\n",
    "            optimizer = torch.optim.Adam(resnet.parameters(),lr=lr)\n",
    "        if(i+1)%10 == 0:\n",
    "            print 'Epoch: [%d/%d] , Batch: [%d/%d] , loss: [%.4f]'%(\n",
    "            epoch+1,epochs,i+1,len(train_dataset)//batch_size , loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on  10000  test images is: 0.3 %\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "resnet.eval()\n",
    "correct = 0 \n",
    "total = 0 \n",
    "\n",
    "for images,labels in test_loader:\n",
    "    images = Variable(images)\n",
    "    outputs = resnet(images)\n",
    "    \n",
    "    _,predicted = torch.max(outputs.data,1)\n",
    "    total+= labels.size(0)\n",
    "    correct = (predicted==labels).sum()\n",
    "\n",
    "print 'Accuracy on ',total,' test images is:',(correct/float(total))*100,'%'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# torch.save(resnet.state_dict(),'resnet.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
